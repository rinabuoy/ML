{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Word Ladder.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPHrAS/W/1FE54E8rxlRWk4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rinabuoy/ML/blob/master/Word_Ladder.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_L3KPIdPI4tS",
        "outputId": "c2c37acc-2594-4396-c142-2291ba92920c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# RUN THIS ONCE IN THE BEGINNING TO INSTALL PYENCHANT\n",
        "!pip install pyenchant\n",
        "!apt-get install libenchant1c2a"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyenchant\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/46/55/810c871d9a556685553ab1ace4a6c580460ca476736829fffe8cfef32a66/pyenchant-3.1.1-py3-none-any.whl (55kB)\n",
            "\r\u001b[K     |█████▉                          | 10kB 14.6MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 20kB 1.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 30kB 2.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 40kB 2.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 51kB 2.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 61kB 1.9MB/s \n",
            "\u001b[?25hInstalling collected packages: pyenchant\n",
            "Successfully installed pyenchant-3.1.1\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  aspell aspell-en dictionaries-common emacsen-common enchant hunspell-en-us\n",
            "  libaspell15 libhunspell-1.6-0 libtext-iconv-perl\n",
            "Suggested packages:\n",
            "  aspell-doc spellutils wordlist hunspell openoffice.org-hunspell\n",
            "  | openoffice.org-core libenchant-voikko\n",
            "The following NEW packages will be installed:\n",
            "  aspell aspell-en dictionaries-common emacsen-common enchant hunspell-en-us\n",
            "  libaspell15 libenchant1c2a libhunspell-1.6-0 libtext-iconv-perl\n",
            "0 upgraded, 10 newly installed, 0 to remove and 11 not upgraded.\n",
            "Need to get 1,310 kB of archives.\n",
            "After this operation, 5,353 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/main amd64 libtext-iconv-perl amd64 1.7-5build6 [13.0 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libaspell15 amd64 0.60.7~20110707-4ubuntu0.1 [309 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic/main amd64 emacsen-common all 2.0.8 [17.6 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic/main amd64 dictionaries-common all 1.27.2 [186 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 aspell amd64 0.60.7~20110707-4ubuntu0.1 [87.6 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu bionic/main amd64 aspell-en all 2017.08.24-0-0.1 [298 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu bionic/main amd64 hunspell-en-us all 1:2017.08.24 [168 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu bionic/main amd64 libhunspell-1.6-0 amd64 1.6.2-1 [154 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu bionic/main amd64 libenchant1c2a amd64 1.6.0-11.1 [64.4 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu bionic/main amd64 enchant amd64 1.6.0-11.1 [12.2 kB]\n",
            "Fetched 1,310 kB in 1s (1,731 kB/s)\n",
            "Preconfiguring packages ...\n",
            "Selecting previously unselected package libtext-iconv-perl.\n",
            "(Reading database ... 144676 files and directories currently installed.)\n",
            "Preparing to unpack .../0-libtext-iconv-perl_1.7-5build6_amd64.deb ...\n",
            "Unpacking libtext-iconv-perl (1.7-5build6) ...\n",
            "Selecting previously unselected package libaspell15:amd64.\n",
            "Preparing to unpack .../1-libaspell15_0.60.7~20110707-4ubuntu0.1_amd64.deb ...\n",
            "Unpacking libaspell15:amd64 (0.60.7~20110707-4ubuntu0.1) ...\n",
            "Selecting previously unselected package emacsen-common.\n",
            "Preparing to unpack .../2-emacsen-common_2.0.8_all.deb ...\n",
            "Unpacking emacsen-common (2.0.8) ...\n",
            "Selecting previously unselected package dictionaries-common.\n",
            "Preparing to unpack .../3-dictionaries-common_1.27.2_all.deb ...\n",
            "Adding 'diversion of /usr/share/dict/words to /usr/share/dict/words.pre-dictionaries-common by dictionaries-common'\n",
            "Unpacking dictionaries-common (1.27.2) ...\n",
            "Selecting previously unselected package aspell.\n",
            "Preparing to unpack .../4-aspell_0.60.7~20110707-4ubuntu0.1_amd64.deb ...\n",
            "Unpacking aspell (0.60.7~20110707-4ubuntu0.1) ...\n",
            "Selecting previously unselected package aspell-en.\n",
            "Preparing to unpack .../5-aspell-en_2017.08.24-0-0.1_all.deb ...\n",
            "Unpacking aspell-en (2017.08.24-0-0.1) ...\n",
            "Selecting previously unselected package hunspell-en-us.\n",
            "Preparing to unpack .../6-hunspell-en-us_1%3a2017.08.24_all.deb ...\n",
            "Unpacking hunspell-en-us (1:2017.08.24) ...\n",
            "Selecting previously unselected package libhunspell-1.6-0:amd64.\n",
            "Preparing to unpack .../7-libhunspell-1.6-0_1.6.2-1_amd64.deb ...\n",
            "Unpacking libhunspell-1.6-0:amd64 (1.6.2-1) ...\n",
            "Selecting previously unselected package libenchant1c2a:amd64.\n",
            "Preparing to unpack .../8-libenchant1c2a_1.6.0-11.1_amd64.deb ...\n",
            "Unpacking libenchant1c2a:amd64 (1.6.0-11.1) ...\n",
            "Selecting previously unselected package enchant.\n",
            "Preparing to unpack .../9-enchant_1.6.0-11.1_amd64.deb ...\n",
            "Unpacking enchant (1.6.0-11.1) ...\n",
            "Setting up libhunspell-1.6-0:amd64 (1.6.2-1) ...\n",
            "Setting up libaspell15:amd64 (0.60.7~20110707-4ubuntu0.1) ...\n",
            "Setting up emacsen-common (2.0.8) ...\n",
            "Setting up libtext-iconv-perl (1.7-5build6) ...\n",
            "Setting up dictionaries-common (1.27.2) ...\n",
            "Setting up aspell (0.60.7~20110707-4ubuntu0.1) ...\n",
            "Setting up hunspell-en-us (1:2017.08.24) ...\n",
            "Setting up libenchant1c2a:amd64 (1.6.0-11.1) ...\n",
            "Setting up aspell-en (2017.08.24-0-0.1) ...\n",
            "Setting up enchant (1.6.0-11.1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.2) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.6/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Processing triggers for dictionaries-common (1.27.2) ...\n",
            "aspell-autobuildhash: processing: en [en-common].\n",
            "aspell-autobuildhash: processing: en [en-variant_0].\n",
            "aspell-autobuildhash: processing: en [en-variant_1].\n",
            "aspell-autobuildhash: processing: en [en-variant_2].\n",
            "aspell-autobuildhash: processing: en [en-w_accents-only].\n",
            "aspell-autobuildhash: processing: en [en-wo_accents-only].\n",
            "aspell-autobuildhash: processing: en [en_AU-variant_0].\n",
            "aspell-autobuildhash: processing: en [en_AU-variant_1].\n",
            "aspell-autobuildhash: processing: en [en_AU-w_accents-only].\n",
            "aspell-autobuildhash: processing: en [en_AU-wo_accents-only].\n",
            "aspell-autobuildhash: processing: en [en_CA-variant_0].\n",
            "aspell-autobuildhash: processing: en [en_CA-variant_1].\n",
            "aspell-autobuildhash: processing: en [en_CA-w_accents-only].\n",
            "aspell-autobuildhash: processing: en [en_CA-wo_accents-only].\n",
            "aspell-autobuildhash: processing: en [en_GB-ise-w_accents-only].\n",
            "aspell-autobuildhash: processing: en [en_GB-ise-wo_accents-only].\n",
            "aspell-autobuildhash: processing: en [en_GB-ize-w_accents-only].\n",
            "aspell-autobuildhash: processing: en [en_GB-ize-wo_accents-only].\n",
            "aspell-autobuildhash: processing: en [en_GB-variant_0].\n",
            "aspell-autobuildhash: processing: en [en_GB-variant_1].\n",
            "aspell-autobuildhash: processing: en [en_US-w_accents-only].\n",
            "aspell-autobuildhash: processing: en [en_US-wo_accents-only].\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j8GTEyklJ5YN"
      },
      "source": [
        "# Successor States"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f0g8igNlJEPV"
      },
      "source": [
        "import enchant, string\n",
        "\n",
        "def successors(state):\n",
        "  \"\"\"\n",
        "  Given a word, find all possible English word results from changing one letter.\n",
        "  Return a list of (action, word) pairs, where action is the index of the\n",
        "  changed letter.\n",
        "  \"\"\"\n",
        "  d = enchant.Dict(\"en_US\")\n",
        "  child_states = []\n",
        "  for i in range(len(state)):\n",
        "    new = [state[:i]+x+state[i+1:] for x in string.ascii_lowercase]\n",
        "    words = [x for x in new if d.check(x) and x != state]\n",
        "    child_states = child_states + [(i, word) for word in words]\n",
        "  return child_states"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E08Wqo0QKBn9"
      },
      "source": [
        "# Node Expansion"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2luyXikhJLmF"
      },
      "source": [
        "from heapq import heappush, heappop\n",
        "\n",
        "def expand(node):\n",
        "  \"\"\"\n",
        "  Given a node, return a list of successor nodes\n",
        "  \"\"\"\n",
        "  state = node['state']\n",
        "  children = []\n",
        "  for successor in successors(state):\n",
        "    children.append({'state':successor[1], 'parent':node,\n",
        "                     'action':successor[0], 'cost':node['cost']+1})\n",
        "  return children\n",
        "\n",
        "\n",
        "def best_first_search(state, goal, f, depth_limit):\n",
        "  \"\"\"\n",
        "  Inputs: Initial state, goal state, priority function, depth limit\n",
        "  Returns node containing goal or None if no goal found within depth limit, \n",
        "  max frontier size, total nodes expanded\n",
        "  \"\"\"\n",
        "  node = {'state':state, 'parent':None, 'action':None, 'cost':0}\n",
        "  frontier = []\n",
        "  heappush(frontier, (f(node, goal), id(node), node))\n",
        "  reached = {state: node}\n",
        "  max_frontier = 1\n",
        "  nodes_expanded = 0\n",
        "\n",
        "  while frontier:\n",
        "    max_frontier = max(max_frontier, len(frontier)) \n",
        "    node = heappop(frontier)[2]\n",
        "\n",
        "    if node['state']==goal: \n",
        "      return node, max_frontier, nodes_expanded \n",
        "    if node['cost']>=depth_limit: \n",
        "      continue \n",
        "    for c in expand(node): \n",
        "      if c['state'] not in reached or c['cost'] <reached[c['state']]['cost']:\n",
        "        reached[c['state']]=c\n",
        "        heappush(frontier, (f(c, goal), id(c), c))\n",
        "    nodes_expanded += 1\n",
        "\n",
        "\n",
        "  return None, max_frontier, nodes_expanded"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OvgYQWt-KIas"
      },
      "source": [
        "# Cost Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rG3B2DnNJUKN"
      },
      "source": [
        "def f_bfs(node, goal):\n",
        "  return id(node)\n",
        "\n",
        "\n",
        "def f_dfs(node, goal):\n",
        "  return -id(node)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3FoYRdI_KMg1"
      },
      "source": [
        "# Utils"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V1GbFSg0JbI8"
      },
      "source": [
        "def sequence(node):\n",
        "  words = [node['state']]\n",
        "  while node['parent'] is not None:\n",
        "    node = node['parent']\n",
        "    words.insert(0, node['state'])\n",
        "  return words\n",
        "\n",
        "def results(solution):\n",
        "  if solution[0] is not None:\n",
        "    words = sequence(solution[0])\n",
        "  else: words = \"No solution!\"\n",
        "  print(words)\n",
        "  print(\"Total cost:\", len(words)-1)\n",
        "  print(\"Max frontier size:\", solution[1])\n",
        "  print(\"Nodes expanded:\", solution[2])\n",
        "  print(\"\")"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z05PVJKaKVqt"
      },
      "source": [
        "# Test - Hit -> Cog"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FlFeZvSNJirw",
        "outputId": "c9ac7e27-03dd-40d2-f718-36f057c5e5ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        }
      },
      "source": [
        "start = 'hit'\n",
        "goal = 'cog'\n",
        "\n",
        "solution = best_first_search(start, goal, f_bfs, float(\"inf\"))\n",
        "print(\"BFS\")\n",
        "results(solution)\n",
        "\n",
        "solution = best_first_search(start, goal, f_dfs, float(\"inf\"))\n",
        "print(\"DFS\")\n",
        "results(solution)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "BFS\n",
            "['hit', 'hot', 'cot', 'cog']\n",
            "Total cost: 3\n",
            "Max frontier size: 492\n",
            "Nodes expanded: 1698\n",
            "\n",
            "DFS\n",
            "['hit', 'wit', 'wot', 'wog', 'cog']\n",
            "Total cost: 4\n",
            "Max frontier size: 840\n",
            "Nodes expanded: 536\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uNkS1lOZKlMF"
      },
      "source": [
        "# Test - Cold -> Warm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zd2lzDbdKpdt",
        "outputId": "796a4823-0709-4276-f790-835499d493c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        }
      },
      "source": [
        "start = 'warm'\n",
        "goal = 'cold'\n",
        "\n",
        "solution = best_first_search(start, goal, f_bfs, float(\"inf\"))\n",
        "print(\"BFS\")\n",
        "results(solution)\n",
        "\n",
        "solution = best_first_search(start, goal, f_dfs, float(\"inf\"))\n",
        "print(\"DFS\")\n",
        "results(solution)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "BFS\n",
            "['warm', 'ware', 'wave', 'gave', 'gape', 'vape', 'vase', 'lase', 'lose', 'lost', 'loot', 'foot', 'fool', 'foll', 'fold', 'cold']\n",
            "Total cost: 15\n",
            "Max frontier size: 447\n",
            "Nodes expanded: 110\n",
            "\n",
            "DFS\n",
            "['warm', 'wart', 'want', 'wand', 'rand', 'rank', 'rink', 'link', 'line', 'lane', 'lake', 'make', 'mace', 'pace', 'pale', 'tale', 'tall', 'toll', 'coll', 'cold']\n",
            "Total cost: 19\n",
            "Max frontier size: 3577\n",
            "Nodes expanded: 3118\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MPAqcCPZKz71"
      },
      "source": [
        "# A* Search"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MnsdTkg9K3ON"
      },
      "source": [
        "# Heuristic Function\n",
        "\n",
        "def f_astar(node, goal):\n",
        "  # YOUR CODE HERE\n",
        "  return sum([c!=goal[i] for i,c in enumerate(node)])"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Z2ZL728K5Nl",
        "outputId": "574c16bc-0cc5-406f-a825-e4f0a4633695",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        }
      },
      "source": [
        "start = 'warm'\n",
        "goal = 'cold'\n",
        "\n",
        "solution = best_first_search(start, goal, f_astar, float(\"inf\"))\n",
        "print(\"A*\")\n",
        "results(solution)\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "A*\n",
            "['warm', 'farm', 'firm', 'film', 'fill', 'foll', 'coll', 'cold']\n",
            "Total cost: 7\n",
            "Max frontier size: 504\n",
            "Nodes expanded: 191\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}